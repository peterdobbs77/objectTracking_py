{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f72d26",
   "metadata": {},
   "source": [
    "# Video analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b51a31",
   "metadata": {},
   "source": [
    "## Panorama\n",
    "\n",
    "Let's play around with making a panorama from a video clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4656d87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESIZED RESOLUTION\n",
    "res_w = 640\n",
    "res_h = 360\n",
    "\n",
    "# PROJECTION CANVAS\n",
    "proj_w = 1000\n",
    "proj_h = 750\n",
    "off_x = 200\n",
    "off_y = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b483b338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blendImages(sourceTransform, referenceTransform):\n",
    "    '''\n",
    "    Naive blending for frame stitching\n",
    "    Input:\n",
    "        - sourceTransform: source frame projected onto reference frame plane\n",
    "        - referenceTransform: reference frame projected onto same space\n",
    "\n",
    "    Output:\n",
    "        - blendedOutput: naive blending result from frame stitching\n",
    "    '''\n",
    "\n",
    "    blendedOutput = referenceTransform\n",
    "    indices = referenceTransform == 0\n",
    "    blendedOutput[indices] = sourceTransform[indices]\n",
    "\n",
    "    return (blendedOutput / blendedOutput.max() * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "973f21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_homography(pts1, pts2, normalization_func=None):\n",
    "    '''\n",
    "    Compute homography that maps from pts1 to pts2 using SVD\n",
    "     \n",
    "    Input: pts1 and pts2 are 3xN matrices for N points in homogeneous\n",
    "    coordinates. \n",
    "    \n",
    "    Output: H is a 3x3 matrix, such that pts2~=H*pts1\n",
    "    '''\n",
    "    n = 4\n",
    "    e = 0\n",
    "    A = np.zeros((2*n, 9))\n",
    "    \n",
    "    # iterate through all points to get A matrix used to solve for H\n",
    "    for i in range(n):\n",
    "        # set u, v, u', v'\n",
    "        u = pts1[0][i]\n",
    "        v = pts1[1][i]\n",
    "        ut = pts2[0][i]\n",
    "        vt = pts2[1][i]\n",
    "        \n",
    "        # set each row to the two equations obtained from each point\n",
    "        A[e] = np.array([ -u, -v, -1, 0, 0, 0, u*ut, v*ut, ut ])\n",
    "        A[e+1] = np.array([ 0, 0, 0, -u, -v, -1, u*vt, v*vt, vt ])\n",
    "        e = e + 2\n",
    "    \n",
    "    # solve the least squares to get H\n",
    "    u,s,vh = np.linalg.svd(A)\n",
    "    h = vh.T[:, -1]\n",
    "    H = h.reshape(3,3)\n",
    "    \n",
    "    return H\n",
    "\n",
    "def auto_homography(Ia, Ib, homography_func=None, normalization_func=None):\n",
    "    '''\n",
    "    Computes a homography that maps points from Ia to Ib\n",
    "\n",
    "    Input: Ia and Ib are images\n",
    "    Output: H is the homography\n",
    "\n",
    "    '''\n",
    "    if Ia.dtype == 'float32' and Ib.dtype == 'float32':\n",
    "        Ia = (Ia*255).astype(np.uint8)\n",
    "        Ib = (Ib*255).astype(np.uint8)\n",
    "    \n",
    "    Ia_gray = cv.cvtColor(Ia,cv.COLOR_BGR2GRAY)\n",
    "    Ib_gray = cv.cvtColor(Ib,cv.COLOR_BGR2GRAY)\n",
    "    mask = np.ones(Ia.shape, dtype=np.uint8)\n",
    "    for y in range(10,50):\n",
    "        for x in range(30,250):\n",
    "            mask[y][x][:] = 0\n",
    "    mask = cv.cvtColor(mask, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initiate SIFT detector\n",
    "    sift = cv.SIFT_create()\n",
    "    \n",
    "    # find the keypoints and descriptors with SIFT\n",
    "    kp_a, des_a = sift.detectAndCompute(Ia_gray,None)\n",
    "    kp_b, des_b = sift.detectAndCompute(Ib_gray,None)    \n",
    "    \n",
    "    # BFMatcher with default params\n",
    "    bf = cv.BFMatcher()\n",
    "    matches = bf.knnMatch(des_a,des_b, k=2)\n",
    "\n",
    "    # Apply ratio test\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < 0.75*n.distance:\n",
    "            good.append(m)\n",
    "   \n",
    "    numMatches = int(len(good))\n",
    "\n",
    "    matches = good\n",
    "\n",
    "    # Xa and Xb are 3xN matrices that contain homogeneous coordinates for the N\n",
    "    # matching points for each image\n",
    "    Xa = np.ones((3,numMatches))\n",
    "    Xb = np.ones((3,numMatches))\n",
    "    \n",
    "    for idx, match_i in enumerate(matches):\n",
    "        Xa[:,idx][0:2] = kp_a[match_i.queryIdx].pt\n",
    "        Xb[:,idx][0:2] = kp_b[match_i.trainIdx].pt\n",
    "\n",
    "    ## RANSAC\n",
    "    niter = 2500\n",
    "    best_score = 0\n",
    "    best_pts1 = np.zeros((3, 4))\n",
    "    best_pts2 = np.zeros((3, 4))\n",
    "\n",
    "    for t in range(niter):\n",
    "        # estimate homography\n",
    "        subset = np.random.choice(numMatches, 4, replace=False)\n",
    "        pts1 = Xa[:,subset]\n",
    "        pts2 = Xb[:,subset]\n",
    "        \n",
    "        H_t = homography_func(pts1, pts2, normalization_func) # edit helper code below (compute_homography)\n",
    "\n",
    "        # score homography\n",
    "        Xb_ = np.dot(H_t, Xa) # project points from first image to second using H\n",
    "        du = Xb_[0,:]/Xb_[2,:] - Xb[0,:]/Xb[2,:]\n",
    "        dv = Xb_[1,:]/Xb_[2,:] - Xb[1,:]/Xb[2,:]\n",
    "\n",
    "        ok_t = np.sqrt(du**2 + dv**2) < 1.5  # you may need to play with this threshold\n",
    "        score_t = sum(ok_t)\n",
    "\n",
    "        if score_t > best_score:\n",
    "            best_score = score_t\n",
    "            best_pts1 = pts1\n",
    "            best_pts2 = pts2\n",
    "            H = H_t\n",
    "            in_idx = ok_t\n",
    "            \n",
    "    # print('best score: {:02f}'.format(best_score))\n",
    "\n",
    "    # Optionally, you may want to re-estimate H based on inliers\n",
    "\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc7f59",
   "metadata": {},
   "source": [
    "Let's start by blending two frames from the video and see how that works for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee028e",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv.VideoCapture('./vid/pull_SBI_2020.mp4')\n",
    "\n",
    "ok, prev_frame = video.read()\n",
    "if not ok:\n",
    "    print('Cannot read video file')\n",
    "    sys.exit()\n",
    "\n",
    "ok, next_frame = video.read()\n",
    "H = auto_homography(prev_frame, next_frame, compute_homography)\n",
    "\n",
    "projSource = cv.warpPerspective(prev_frame, H, (proj_w, proj_h))\n",
    "projReference = cv.warpPerspective(next_frame, H, (proj_w, proj_h))\n",
    "\n",
    "blend = blendImages(projSource, projReference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b54d13f",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "video = cv.VideoCapture('./vid/pull_SBI_2020.mp4')\n",
    "\n",
    "ok, prev_frame = video.read()\n",
    "if not ok:\n",
    "    print('Cannot read video file')\n",
    "    sys.exit()\n",
    "\n",
    "ok, next_frame = video.read()\n",
    "H = auto_homography(prev_frame, next_frame, compute_homography)\n",
    "\n",
    "projSource = cv.warpPerspective(prev_frame, H, (proj_w, proj_h))\n",
    "projReference = cv.warpPerspective(next_frame, H, (proj_w, proj_h))\n",
    "\n",
    "blend = blendImages(projSource, projReference)\n",
    "\n",
    "while True:\n",
    "    ok, next_frame = video.read()\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    H = auto_homography(prev_frame, next_frame, compute_homography)\n",
    "\n",
    "    projSource = cv.warpPerspective(next_frame, H, (proj_w, proj_h))\n",
    "\n",
    "    blend = blendImages(projSource, blend)\n",
    "\n",
    "    # show the output frame\n",
    "    cv.imshow(\"Blended Frames\", blend)\n",
    "\n",
    "    prev_frame = next_frame.copy()\n",
    "\n",
    "    key = cv.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a3a315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1080, 1920, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f29f107c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"\", prev_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f3987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115ea755",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# cleanup\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mvideo\u001b[49m.release()\n\u001b[32m      3\u001b[39m cv.destroyAllWindows()\n",
      "\u001b[31mNameError\u001b[39m: name 'video' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# cleanup\n",
    "video.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
